{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy import ndimage\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nfrom glob import glob\n\n\nimport tensorflow as tf\nimport keras\nfrom keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D,BatchNormalization\nfrom keras.layers import Conv2DTranspose, Dropout,GlobalAveragePooling2D\n\nfrom keras.layers import concatenate, GaussianNoise,UpSampling2D\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\nfrom keras import regularizers\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.losses import binary_crossentropy,categorical_crossentropy\n\n\n\nimport cv2\nimport os\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_base = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\nprint(train_base.shape)\ntrain_base.head(3)\n#12568\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image id and class id are two seperate entities and it makes it easier to split them up in two columns\n#train_base = train_base[train_base['EncodedPixels'].notnull()].reset_index(drop=True)\ntrain_base['ImageId'] = train_base['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_base['ClassId'] = train_base['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_base['hasMask'] = ~ train_base['EncodedPixels'].isna()\ntrain_base.head(2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count_df = train_base.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = pd.merge(train_base,mask_count_df, how='left',  left_on='ImageId', right_on='ImageId',)\nbase.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_full = base[base['hasMask_y']>0]\nbase_full.fillna(-1, inplace = True)\nbase_full = pd.DataFrame(base_full).reset_index()\nbase_full.head() #samples with at least one mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/severstal-steel-defect-detection/' # directory of training images\npretrained_model_path = '../input/severstal-pretrained-model/ResUNetSteel_z.h5' # path of pretrained model\nmodel_save_path = './ResUNetSteel_w800e50_z.h5' # path of model to save\ntrain_image_dir = os.path.join(train_dir, 'train_images') # ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a dict of all the masks\nmasks = {}\nfor index, row in base_full[base_full['EncodedPixels']!=-1].iterrows():\n    masks[row['ImageId_ClassId']] = row['EncodedPixels']\n\ntrain_image_ids = base_full['ImageId'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_full[base_full['EncodedPixels'] == -1]['ClassId'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"5865/(5865+801)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_full[base_full['EncodedPixels'] != -1]['ClassId'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_def_1 = base_full[(base_full['EncodedPixels'] !=-1) & (base_full['hasMask_y'] == 1)]\nbase_def_1.reset_index(drop = True, inplace = True)\nbase_def_1.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test = StratifiedShuffleSplit(n_splits = 1, test_size = 0.3, random_state = 222)\nX = base_def_1['ImageId']\ny = base_def_1['ClassId']\nfor train_index, test_index in train_test.split(X,y):\n    X_train, X_val = X[train_index], X[test_index]\n    Y_train, Y_val = y[train_index], y[test_index]\nX_train_1 = X_train.reset_index(drop = True)   \nX_val_1 = X_val.reset_index(drop = True)\n#Y_val = Y_val.reset_index(drop = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multidef = base_full[(base_full['EncodedPixels'] !=-1) & (base_full['hasMask_y'] > 1)]\nimage_ids = multidef['ImageId'].unique()\nX_train, X_val = train_test_split(image_ids, test_size=0.3, random_state=222)\n#X_val, X_test = train_test_split(X_val, test_size=0.4, random_state=222)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate([X_train_1, X_train])\nX_val = np.concatenate([X_val_1, X_val])\n#X_test = np.concatenate([X_test_1, X_test])\nprint(len(X_train), len(X_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_h = 128\nimg_w = 800","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://www.kaggle.com/robertkag/rle-to-mask-converter\ndef rle_to_mask(rle_string,height,width):\n    '''\n    convert RLE(run length encoding) string to numpy array\n\n    Parameters: \n    rleString (str): Description of arg1 \n    height (int): height of the mask\n    width (int): width of the mask \n\n    Returns: \n    numpy.array: numpy array of the mask\n    '''\n    rows, cols = height, width\n    if rle_string == -1:\n        return np.zeros((height, width))\n    else:\n        rleNumbers = [int(numstring) for numstring in rle_string.split(' ')]\n        rlePairs = np.array(rleNumbers).reshape(-1,2)\n        img = np.zeros(rows*cols,dtype=np.uint8)\n        for index,length in rlePairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n        return img\n# Thanks to the authors of: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\ndef mask_to_rle(mask):\n    '''\n    Convert a mask into RLE\n    \n    Parameters: \n    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n\n    Returns: \n    sring: run length encoding \n    '''\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n##Data Generator\n#To push the data to our model, we will create a custom data generator. A generator lets us load data progressively, instead of loading it all into memory at once. A custom generator allows us to also fit in more customization during the time of loading the data. As the model is being procssed in the GPU, we can use a custom generator to pre-process images via a generator. At this time, we can also take advantage multiple processors to parallelize our pre-processing.\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, list_ids, labels, image_dir, batch_size=10,\n                 img_h=img_h, img_w=img_w, shuffle=True):\n        \n        self.list_ids = list_ids\n        self.labels = labels\n        self.image_dir = image_dir\n        self.batch_size = batch_size\n        self.img_h = img_h\n        self.img_w = img_w\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_ids)) / self.batch_size)\n    \n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        list_ids_temp = [self.list_ids[k] for k in indexes]\n        # generate data\n        X, y = self.__data_generation(list_ids_temp)\n        # return data \n        return X, y\n    \n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.list_ids))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, list_ids_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n        y = np.empty((self.batch_size, self.img_h, self.img_w, 5))\n        \n        for idx, id in enumerate(list_ids_temp):\n            file_path =  os.path.join(self.image_dir, id)\n            image = cv2.imread(file_path, 0)\n            image_resized = cv2.resize(image, (self.img_w, self.img_h))\n            image_resized = np.array(image_resized, dtype=np.float64)\n            # standardization of the image\n            image_resized -= image_resized.mean()\n            image_resized /= image_resized.std()\n            \n            mask = np.empty((self.img_h, self.img_w, 5))\n            mark =  np.empty((self.img_h, self.img_w))\n            \n            for idm, image_class in enumerate(['1','2','3','4']):\n                rle = self.labels.get(id + '_' + image_class)\n                # if there is no mask create empty mask\n                if rle is None:\n                    class_mask = np.zeros((1600, 256))\n                else:\n                    class_mask = rle_to_mask(rle, width=1600, height=256)\n             \n                class_mask_resized = cv2.resize(class_mask, (self.img_w, self.img_h))\n                mark += class_mask_resized\n                mask[...,idm] = class_mask_resized\n            mark = (mark==0).astype(int)    \n            mask[...,4] = mark\n            X[idx,] = np.expand_dims(image_resized, axis=2)\n            y[idx,] = mask\n        \n        # normalize Y\n        y = (y > 0).astype(int)\n            \n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 10\nparams = {'img_h': img_h,\n          'img_w': img_w,\n          'image_dir': train_image_dir,\n          'batch_size': batch_size,\n          'shuffle': True}\n\n# Get Generators\ntraining_generator = DataGenerator(X_train, masks, **params)\nvalidation_generator = DataGenerator(X_val, masks, **params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Callbacks\nearly_stopping_monitor = EarlyStopping(monitor='dice_coef',patience = 5)\ncheck = ModelCheckpoint(\n    'model.h5', \n    monitor='val_loss', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nred_rl = ReduceLROnPlateau(factor=0.3, patience=3, min_lr=0.000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_single_channel( y_true,y_pred, eps = 1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + eps) / (K.sum(y_true_f) + K.sum(y_pred_f) + eps)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true,y_pred):\n    treshhold = 0.5\n    batch_size = 10\n    channel_num = 5\n    refer_pos = [2,2,1,1.5]\n    \n    dice_batch = []\n    for i in range(batch_size):\n        dice = []\n        for j in range(channel_num):\n            pred =  y_pred[i,:,:,j]\n            tr = y_true[i,:,:,j]\n            if tr is np.zeros:\n                dice.append(dice_single_channel(tr, pred))\n            else:\n                if j==0:\n                     dice.append(2*dice_single_channel(tr, pred))\n                if j==1:\n                     dice.append(2.5*dice_single_channel(tr, pred))        \n                if j == 3:\n                     dice.append(1.5*dice_single_channel(tr, pred))\n                else:\n                      dice.append(dice_single_channel(tr, pred))\n        dice =sum(dice)/channel_num\n        dice_batch.append(dice)\n    return  sum(dice_batch)/batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cce(y_true, y_pred):\n    return 0.7*categorical_crossentropy(y_true, y_pred) - 0.25* dice_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_Unet():\n\n\n    inputs = Input((None, None, 1))\n    bnorm1 = BatchNormalization()(inputs)\n    conv1 = Conv2D(32, (3, 3),init='he_uniform', W_regularizer=regularizers.l2(0.0001), activation='relu', padding='same')(bnorm1)\n    conv1 = Conv2D(32, (3, 3), activation='relu', W_regularizer=regularizers.l2(0.0001), padding='same')(conv1)\n    #drop1 = Dropout(0.25)(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3),activation='relu', padding='same')(pool1)\n    bnorm2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(64, (3, 3),activation='relu', padding='same')(bnorm2)\n\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    bnorm3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(bnorm3)\n\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    bnorm4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(256, (3, 3),  activation='relu', padding='same')(bnorm4)\n\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    bnorm5 = BatchNormalization()(conv5)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(bnorm5)\n\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    bnorm6 = BatchNormalization()(conv6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(bnorm6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    bnorm7 = BatchNormalization()(conv7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(bnorm7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    bnorm8 = BatchNormalization()(conv8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(bnorm8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    bnorm9 = BatchNormalization()(conv9)\n    conv9 = Conv2D(32, (3, 3),  activation='relu', padding='same')(bnorm9)\n\n    conv10 = Conv2D(5, (1, 1), activation='softmax')(conv9)\n\n    model = Model(inputs=[inputs], outputs=[conv10])\n    return model\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_Unet()\nmodel.compile(Adam(0.0001),\n              loss=cce, metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhistory = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=15, verbose=1,\n                             shuffle=True,callbacks = [check,red_rl])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('modelUnet-cat+dice.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Block for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# return tensor in the right shape for prediction \ndef decode_test_image(img_dir, img_h, img_w, channels=1):\n\n    X = np.empty((1, img_h, img_w, channels))\n    # Store sample\n    image = cv2.imread(img_dir, 0)\n    image_resized = cv2.resize(image, (img_w, img_h))\n    image_resized = np.array(image_resized, dtype=np.float64)\n    # normalize image\n    image_resized -= image_resized.mean()\n    image_resized /= image_resized.std()\n    \n    X[0,] = np.expand_dims(image_resized, axis=2)\n\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samp = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nsamp['ImageId'] = samp['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\nX_test = samp['ImageId'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = '../input/severstal-steel-defect-detection/test_images/'\ntest_files = []\nfor idx, id in enumerate(X_test):\n    file_path = os.path.join(test_dir, id)\n    test_files.append(file_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this is an awesome little function to remove small spots in our predictions\n\nfrom skimage import morphology\n\ndef remove_small_regions(img, size):\n    \"\"\"Morphologically removes small (less than size) connected regions of 0s or 1s.\"\"\"\n    img = morphology.remove_small_objects(img, size)\n    img = morphology.remove_small_holes(img, size)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = []\n\n# a function to apply all the processing steps necessery to each of the individual masks\ndef process_pred_mask(pred_mask):\n    \n    pred_mask = cv2.resize(pred_mask.astype('float32'),(1600, 256))\n    pred_mask = (pred_mask > .5).astype(int)\n    pred_mask = remove_small_regions(pred_mask, 0.02 * np.prod(512)) * 255\n    pred_mask = mask_to_rle(pred_mask)\n    \n    return pred_mask\n\n# loop over all the test images\nfor f in test_files:\n    # get test tensor, output is in shape: (1, 256, 512, 3)\n    test = decode_test_image(f, img_h, img_w,1) \n    # get prediction, output is in shape: (1, 256, 512, 4)\n    pred_masks = model.predict(test) \n    # get a list of masks with shape: 256, 512\n    pred_masks = [pred_masks[0][...,i] for i in range(0,4)]\n    # apply all the processing steps to each of the mask\n    pred_masks = [process_pred_mask(pred_mask) for pred_mask in pred_masks]\n    # get our image id\n    idx = f.split('/')[-1]\n    # create ImageId_ClassId and get the EncodedPixels for the class ID, and append to our submissions list\n    [submission.append((idx+'_%s' % (k+1), pred_mask)) for k, pred_mask in enumerate(pred_masks)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_test = pd.DataFrame(submission, columns=['ImageId_ClassId', 'EncodedPixels'])\nsubmission_test[ submission_test['EncodedPixels'] != ''].head()\n\nsubmission_test.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\nFileLinks('.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = '../input/severstal-steel-defect-detection/train_images/'\ntest_files = []\nfor idx, id in enumerate(X_val):\n    file_path = os.path.join(test_dir, id)\n    test_files.append(file_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in test_files:\n    # get test tensor, output is in shape: (1, 256, 512, 3)\n    test = decode_test_image(f, img_h, img_w,1) \n    # get prediction, output is in shape: (1, 256, 512, 4)\n    pred_masks = model.predict(test) \n    # get a list of masks with shape: 256, 512\n    pred_masks = [pred_masks[0][...,i] for i in range(0,4)]\n    # apply all the processing steps to each of the mask\n    pred_masks = [process_pred_mask(pred_mask) for pred_mask in pred_masks]\n    # get our image id\n    idx = f.split('/')[-1]\n    # create ImageId_ClassId and get the EncodedPixels for the class ID, and append to our submissions list\n    [submission.append((idx+'_%s' % (k+1), pred_mask)) for k, pred_mask in enumerate(pred_masks)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_val = pd.DataFrame(submission, columns=['ImageId_ClassId', 'EncodedPixels'])\nsubmission_val[ submission_val['EncodedPixels'] != ''].head()\n\nsubmission_val.to_csv('./submission_val.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_unet = submission_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_unet.fillna(-1, inplace = True)\nsubmission_unet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef_q(y_true, y_pred):\n    \n    intersection = sum(y_true * y_pred)\n    return (2. * intersection + 1) / (sum(y_true) + sum(y_pred) + 1)\n\n\n\ndef dice_float(base,num):\n   \n    y_true = rle2mask(base['rle_true'][num])\n    y_pred = rle2mask(base['rle_pred'][num])\n    \n    dice = dice_coef_q(y_true, y_pred)\n    return dice\n\n    \"\"\"\n    with tf.Session() as sess:\n        init = tf.global_variables_initializer()\n        sess.run(init)\n        return dice.eval()\n       \n    \"\"\" \ndef dice_column(base):\n    dice_column = []\n    for i in range(base.shape[0]):\n        dice = dice_float(base, i)\n        dice_column.append(dice)\n    return dice_column\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_result = submission_unet.merge(base_full, left_on = 'ImageId_ClassId', right_on = 'ImageId_ClassId' )\nunet_result.rename(columns={'EncodedPixels_x': 'rle_pred', 'EncodedPixels_y': 'rle_true'}, inplace=True)\nunet_result = unet_result[['ImageId_ClassId','rle_pred','rle_true','ImageId','ClassId']]\nunet_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle):\n    # CONVERT RLE TO MASK \n    if rle== -1: \n        return np.zeros((256*1600),dtype=np.uint8)\n    else:\n        height= 256\n        width = 1600\n        mask= np.zeros( width*height ,dtype=np.uint8)\n\n        array = np.asarray([int(x) for x in rle.split()])\n        starts = array[0::2]-1\n        lengths = array[1::2]    \n        for index, start in enumerate(starts):\n            mask[int(start):int(start+lengths[index])] = 1\n\n        return mask.reshape( (height*width), order='F' )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_total = dice_column(unet_result)\nunet_result['dice'] = unet_total\nunet_result.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_result.to_csv('unet_result_cat.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_result['dice'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_result[['ClassId','dice']].groupby('ClassId').agg({'mean','count'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_nan = unet_result[unet_result['rle_true']==-1]\nunet_nan[['ClassId','dice']].groupby('ClassId').agg('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_nan = unet_result[unet_result['rle_pred']==-1]\nunet_nan[['ClassId','dice']].groupby('ClassId').agg('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_nan = unet_result[unet_result['rle_true']!=-1]\nunet_nan[['ClassId','dice']].groupby('ClassId').agg('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_result.to_csv('unet_reslt.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Files(,)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}